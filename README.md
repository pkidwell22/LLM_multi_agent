# LLM_Multi_Agent (Windows + llama.cpp)

Literature-focused multi-agent RAG system.
- Retrieval: FAISS (Gutenberg)
- LLMs: local GGUF via llama.cpp
- FastAPI server: \server/rag_server.py\

> Large files (models/, indices) are ignored. Use tools/grab_gguf.py to fetch models.
